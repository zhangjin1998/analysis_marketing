import os
import re
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from functools import lru_cache

CACHE_DAILY_DIR = "analyse_marketing/cache/daily"
CANDIDATE_CSV = "analyse_marketing/out/daily_candidates.csv"


def _list_all_codes(limit: int = 200) -> List[str]:
    """ä» analyse_marketing ç¼“å­˜åˆ—å‡ºéƒ¨åˆ†ä»£ç ä½œä¸ºå€™é€‰ï¼ˆè‹¥æœªäº§å‡ºå€™é€‰æ± ï¼‰ã€‚"""
    if os.path.exists(CANDIDATE_CSV):
        try:
            df = pd.read_csv(CANDIDATE_CSV)
            # å…¼å®¹ä¸åŒåˆ—åï¼ˆts_code / codeï¼‰
            if "ts_code" in df.columns:
                codes = df["ts_code"].dropna().astype(str).tolist()
            elif "code" in df.columns:
                codes = df["code"].dropna().astype(str).tolist()
            else:
                codes = []
            return codes[:limit] if limit else codes
        except Exception:
            pass

    if not os.path.exists(CACHE_DAILY_DIR):
        return []
    files = [f for f in os.listdir(CACHE_DAILY_DIR) if f.endswith(".parquet")]
    codes = [os.path.splitext(f)[0] for f in files]
    return codes[:limit] if limit else codes


def list_cache_codes(limit: int = 0) -> List[str]:
    """åˆ—å‡ºç¼“å­˜ä¸­å…¨éƒ¨è‚¡ç¥¨ä»£ç ï¼ˆå¿½ç•¥å€™é€‰æ± ï¼‰ã€‚limit=0 è¡¨ç¤ºä¸é™åˆ¶ã€‚"""
    if not os.path.exists(CACHE_DAILY_DIR):
        return []
    files = [f for f in os.listdir(CACHE_DAILY_DIR) if f.endswith(".parquet")]
    codes = [os.path.splitext(f)[0] for f in files]
    return codes if not limit or limit <= 0 else codes[:limit]


def _to_variants(ts_code: str) -> List[str]:
    """ts_code å˜ä½“ï¼š000001.SZ / 000001_SZ / åŸæ ·ã€‚"""
    variants = {ts_code}
    if '.' in ts_code:
        variants.add(ts_code.replace('.', '_'))
    if '_' in ts_code:
        variants.add(ts_code.replace('_', '.'))
    return list(variants)


@lru_cache(maxsize=1)
def load_st_code_set(cache_csv: str = "data/patterns/st_codes.csv") -> set:
    """åŠ è½½/æ„å»º ST è‚¡ç¥¨ä»£ç é›†åˆï¼ˆåŒ…å«ç‚¹å·ä¸ä¸‹åˆ’çº¿ä¸¤ç§å˜ä½“ï¼‰ã€‚
    éœ€è¦ TUSHARE_TOKENï¼›è‹¥ä¸å¯ç”¨åˆ™è¿”å›ç©ºé›†åˆã€‚
    """
    os.makedirs(os.path.dirname(cache_csv), exist_ok=True)
    try:
        if os.path.exists(cache_csv):
            df = pd.read_csv(cache_csv)
            codes = set(df["ts_code"].astype(str).tolist())
            # å˜ä½“
            out = set()
            for c in codes:
                out.update(_to_variants(c))
            return out
    except Exception:
        pass

    token = os.environ.get("TUSHARE_TOKEN")
    if not token:
        return set()
    try:
        import tushare as ts
        pro = ts.pro_api(token)
        basics = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,list_date')
        basics = basics.dropna(subset=['ts_code','name'])
        st_df = basics[basics['name'].str.contains('ST')].copy()
        if not st_df.empty:
            st_df.to_csv(cache_csv, index=False, encoding='utf-8-sig')
        codes = set(st_df['ts_code'].astype(str).tolist())
        out = set()
        for c in codes:
            out.update(_to_variants(c))
        return out
    except Exception:
        return set()


def _load_panel_from_cache(codes: List[str]) -> Dict[str, pd.DataFrame]:
    """åŠ è½½ OHLCV é¢æ¿ï¼Œè¿”å› {code: df[open,high,low,close,volume]}ã€‚"""
    panels: Dict[str, pd.DataFrame] = {}
    for code in codes:
        path = os.path.join(CACHE_DAILY_DIR, f"{code}.parquet")
        if not os.path.exists(path):
            # å°è¯•å¦ä¸€ç§å‘½åï¼ˆç‚¹å· vs ä¸‹åˆ’çº¿ï¼‰
            alt = os.path.join(CACHE_DAILY_DIR, f"{code.replace('.', '_')}.parquet")
            if os.path.exists(alt):
                path = alt
            else:
                continue
        try:
            df = pd.read_parquet(path)
            # å…¼å®¹å­—æ®µå
            col_map = {
                "open": ["open", "OPEN"],
                "high": ["high", "HIGH"],
                "low": ["low", "LOW"],
                "close": ["close", "CLOSE"],
                "vol": ["vol", "volume", "VOL", "VOLUME"],
            }
            norm = {}
            for k, aliases in col_map.items():
                for a in aliases:
                    if a in df.columns:
                        norm[k] = df[a]
                        break
            if len(norm) < 4:
                continue
            nd = pd.DataFrame(norm)
            # ç´¢å¼•ä¸ºæ—¥æœŸ/äº¤æ˜“æ—¥ï¼ˆæ•´æ•°æˆ–æ—¶é—´æˆ³éƒ½å¯ï¼‰
            nd = nd.sort_index()
            panels[code] = nd
        except Exception:
            continue
    return panels


def _body(ohlc: pd.DataFrame) -> pd.Series:
    return (ohlc["close"] - ohlc["open"]).abs()


def _upper_shadow(ohlc: pd.DataFrame) -> pd.Series:
    return ohlc["high"] - ohlc[["open", "close"]].max(axis=1)


def _lower_shadow(ohlc: pd.DataFrame) -> pd.Series:
    return ohlc[["open", "close"]].min(axis=1) - ohlc["low"]


def pattern_hammer(ohlc: pd.DataFrame) -> pd.Series:
    """é”¤å­çº¿ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼šä¸‹å½±>=2å€å®ä½“ï¼Œä¸Šå½±è¾ƒçŸ­ï¼Œå®ä½“è¾ƒå°ã€‚"""
    body = _body(ohlc)
    upper = _upper_shadow(ohlc)
    lower = _lower_shadow(ohlc)
    body_med = body.rolling(20, min_periods=5).median()
    is_small_body = body <= body_med
    cond = (lower >= 2 * body) & (upper <= body * 0.5) & is_small_body
    return cond.fillna(False)


def pattern_bullish_engulfing(ohlc: pd.DataFrame) -> pd.Series:
    """çœ‹æ¶¨åæ²¡ï¼šä»Šæ—¥é˜³çº¿ï¼Œå®ä½“åŒ…ä½æ˜¨æ—¥å®ä½“ã€‚"""
    prev_open = ohlc["open"].shift(1)
    prev_close = ohlc["close"].shift(1)
    today_bull = ohlc["close"] > ohlc["open"]
    prev_body = (prev_close - prev_open).abs()
    today_body = _body(ohlc)
    engulf = (ohlc["open"] <= prev_close) & (ohlc["close"] >= prev_open) & (today_body > prev_body)
    return (today_bull & engulf).fillna(False)


def pattern_three_white_soldiers(ohlc: pd.DataFrame) -> pd.Series:
    """ä¸‰è¿é˜³ï¼ˆç®€åŒ–ï¼‰ï¼šè¿ç»­ä¸‰æ—¥æ”¶é˜³ä¸”æ”¶ç›˜ä¾æ¬¡æŠ¬é«˜ã€‚"""
    up = ohlc["close"] > ohlc["open"]
    cond = up & up.shift(1) & up.shift(2)
    higher_close = (ohlc["close"] > ohlc["close"].shift(1)) & (ohlc["close"].shift(1) > ohlc["close"].shift(2))
    return (cond & higher_close).fillna(False)


def pattern_ma5_cross_ma20(ohlc: pd.DataFrame) -> pd.Series:
    ma5 = ohlc["close"].rolling(5).mean()
    ma20 = ohlc["close"].rolling(20).mean()
    cross_up = (ma5 > ma20) & (ma5.shift(1) <= ma20.shift(1))
    return cross_up.fillna(False)


def pattern_break_20d_high_with_volume(ohlc: pd.DataFrame) -> pd.Series:
    high20 = ohlc["close"].rolling(20).max()
    vr = ohlc["vol"] if "vol" in ohlc.columns else (ohlc["close"] * 0)
    vr = vr.astype(float)
    vol_ma20 = vr.rolling(20).mean()
    cond = (ohlc["close"] >= high20) & (vr >= 1.5 * vol_ma20)
    return cond.fillna(False)


def pattern_break_previous_range(ohlc: pd.DataFrame, lookback: int = 10) -> pd.Series:
    """çªç ´è¿‘10æ—¥éœ‡è¡åŒºé—´ï¼ˆæ”¶ç›˜>è¿‘10æ—¥é«˜ç‚¹ï¼Œä¸”è¿‘10æ—¥æŒ¯å¹…è¾ƒä½ï¼‰ã€‚"""
    high_n = ohlc["high"].rolling(lookback).max()
    low_n = ohlc["low"].rolling(lookback).min()
    range_pct = (high_n - low_n) / ohlc["close"].rolling(lookback).mean()
    cond = (ohlc["close"] >= high_n) & (range_pct <= 0.06)
    return cond.fillna(False)


PATTERN_MAP = {
    "é”¤å­çº¿": pattern_hammer,
    "çœ‹æ¶¨åæ²¡": pattern_bullish_engulfing,
    "ä¸‰è¿é˜³": pattern_three_white_soldiers,
    "MA5ä¸Šç©¿MA20": pattern_ma5_cross_ma20,
    "æ”¾é‡çªç ´": pattern_break_20d_high_with_volume,
    "çªç ´20æ—¥æ–°é«˜": pattern_break_20d_high_with_volume,
    "åŒºé—´çªç ´": pattern_break_previous_range,
}


def _normalize_patterns(pattern_names: List[str]) -> List[str]:
    if not pattern_names:
        return []
    names = []
    for p in pattern_names:
        p = p.strip()
        if not p:
            continue
        # ç®€å•å½’ä¸€åŒ–
        if p in ("é‡‘å‰", "maé‡‘å‰", "ma5é‡‘å‰"):
            p = "MA5ä¸Šç©¿MA20"
        if p in ("æ–°é«˜çªç ´", "20æ—¥æ–°é«˜", "çªç ´æ–°é«˜"):
            p = "çªç ´20æ—¥æ–°é«˜"
        if p in ("æ”¾é‡æ–°é«˜", "æ”¾é‡ä¸Šç ´"):
            p = "æ”¾é‡çªç ´"
        # å¼ºåŠ¿åå¹³å°ï¼ˆåå‘¨ä¸Šæ¶¨>=60% ä¸”è¿‘1-3å‘¨å¹³å°éœ‡è¡ï¼‰
        if ("åå‘¨" in p) or ("10å‘¨" in p) or ("æ¶¨60" in p) or ("60%" in p) or ("å¼ºåŠ¿å¹³å°" in p) or ("å¼ºåŠ¿åå¹³å°" in p) or ("å¹³å°éœ‡è¡" in p and ("å" in p or "10" in p)):
            p = "å¼ºåŠ¿åå¹³å°"
        names.append(p)
    return names


def detect_patterns_on_candidates(pattern_names: List[str], limit: int = 200, exclude_st: bool = True) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    åœ¨å€™é€‰æ± ä¸Šæ£€æµ‹å½¢æ€ã€‚
    è¿”å›ï¼š
      picks: DataFrame(index=date, columns=code, boolean) æœ€æ–°ä¸€è¡Œä¸ºç­›é€‰ç»“æœ
      table: DataFrame çºµå‘åˆ—å‡º code ä¸å‘½ä¸­å½¢æ€
    """
    names = _normalize_patterns(pattern_names)
    if not names:
        names = ["MA5ä¸Šç©¿MA20", "é”¤å­çº¿", "çœ‹æ¶¨åæ²¡"]

    codes = _list_all_codes(limit=limit)
    if exclude_st:
        st_set = load_st_code_set()
        if st_set:
            codes = [c for c in codes if c not in st_set]
    panels = _load_panel_from_cache(codes)
    if not panels:
        return pd.DataFrame(), pd.DataFrame()

    # å¯¹æ¯åªè‚¡ç¥¨è®¡ç®—æ¯ä¸ªå½¢æ€å¸ƒå°”åºåˆ—
    last_index = None
    pattern_hits: Dict[str, Dict[str, bool]] = {}
    picks_matrix = {}

    for code, ohlc in panels.items():
        hit_dict: Dict[str, bool] = {}
        per_code_flags = []
        for name in names:
            fn = PATTERN_MAP.get(name)
            if fn is None:
                continue
            flags = fn(ohlc)
            per_code_flags.append(flags)
            if last_index is None and len(flags.index) > 0:
                last_index = flags.index[-1]
            hit_dict[name] = bool(flags.iloc[-1]) if len(flags) else False
        pattern_hits[code] = hit_dict
        # è”åˆæ¡ä»¶ï¼šæ‰€é€‰å½¢æ€å…¨éƒ¨æ»¡è¶³
        if per_code_flags:
            all_ok = per_code_flags[0]
            for f in per_code_flags[1:]:
                all_ok = all_ok & f
            picks_matrix[code] = all_ok

    if not picks_matrix:
        return pd.DataFrame(), pd.DataFrame()

    picks_df = pd.DataFrame(picks_matrix)
    # ä»…ä¿ç•™æœ€åä¸€è¡Œç”¨äºé€‰è‚¡
    if last_index is not None and last_index in picks_df.index:
        picks_df = picks_df.loc[[last_index]]

    # æ±‡æ€»è¡¨ï¼šä»…åˆ—å‡ºå‘½ä¸­çš„å½¢æ€
    rows = []
    if picks_df.shape[0] > 0:
        latest = picks_df.iloc[-1]
        for code, is_pick in latest.items():
            if bool(is_pick):
                hit_list = [n for n, v in pattern_hits.get(code, {}).items() if v]
                rows.append({"code": code, "patterns": ", ".join(hit_list)})
    table = pd.DataFrame(rows)
    return picks_df, table


def detect_patterns_on_all(pattern_names: List[str], limit: int = 0, exclude_st: bool = True) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """åœ¨å…¨ç¼“å­˜è‚¡ç¥¨ä¸Šæ£€æµ‹å½¢æ€ã€‚limit=0 è¡¨ç¤ºä¸é™åˆ¶ã€‚"""
    names = _normalize_patterns(pattern_names)
    if not names:
        names = ["MA5ä¸Šç©¿MA20", "é”¤å­çº¿", "çœ‹æ¶¨åæ²¡"]

    codes = list_cache_codes(limit=limit)
    if exclude_st:
        st_set = load_st_code_set()
        if st_set:
            codes = [c for c in codes if c not in st_set]
    panels = _load_panel_from_cache(codes)
    if not panels:
        return pd.DataFrame(), pd.DataFrame()

    last_index = None
    pattern_hits: Dict[str, Dict[str, bool]] = {}
    picks_matrix = {}

    for code, ohlc in panels.items():
        hit_dict: Dict[str, bool] = {}
        per_code_flags = []
        for name in names:
            fn = PATTERN_MAP.get(name)
            if fn is None:
                continue
            flags = fn(ohlc)
            per_code_flags.append(flags)
            if last_index is None and len(flags.index) > 0:
                last_index = flags.index[-1]
            hit_dict[name] = bool(flags.iloc[-1]) if len(flags) else False
        pattern_hits[code] = hit_dict
        if per_code_flags:
            all_ok = per_code_flags[0]
            for f in per_code_flags[1:]:
                all_ok = all_ok & f
            picks_matrix[code] = all_ok

    if not picks_matrix:
        return pd.DataFrame(), pd.DataFrame()

    picks_df = pd.DataFrame(picks_matrix)
    if last_index is not None and last_index in picks_df.index:
        picks_df = picks_df.loc[[last_index]]

    rows = []
    if picks_df.shape[0] > 0:
        latest = picks_df.iloc[-1]
        for code, is_pick in latest.items():
            if bool(is_pick):
                hit_list = [n for n, v in pattern_hits.get(code, {}).items() if v]
                rows.append({"code": code, "patterns": ", ".join(hit_list)})
    table = pd.DataFrame(rows)
    return picks_df, table


def format_pattern_result(picks_df: pd.DataFrame, table: pd.DataFrame, top_k: int = 20) -> str:
    if picks_df is None or picks_df.empty:
        return "ä»Šæ—¥æœªå‘½ä¸­æ‰€é€‰å½¢æ€"
    latest = picks_df.iloc[-1]
    picked_codes = [c for c, v in latest.items() if bool(v)]
    if not picked_codes:
        return "ä»Šæ—¥æœªå‘½ä¸­æ‰€é€‰å½¢æ€"
    picked_codes = picked_codes[:top_k]
    lines = ["ğŸ“‹ å½¢æ€é€‰è‚¡ç»“æœ", f"å…± {len(picked_codes)} åªï¼Œå±•ç¤ºå‰ {min(top_k, len(picked_codes))} åª:"]
    for i, code in enumerate(picked_codes, 1):
        patterns = None
        if table is not None and not table.empty:
            row = table[table["code"] == code]
            if not row.empty:
                patterns = row.iloc[0]["patterns"]
        lines.append(f"{i}. {code}  | å‘½ä¸­: {patterns or '-'}")
    return "\n".join(lines)


# ===== æ‰©å±•å½¢æ€ï¼šå¼ºåŠ¿åå¹³å° =====

def pattern_strong_run_then_platform(ohlc: pd.DataFrame, run_days: int = 75, run_thresh: float = 0.60,
                                     plat_min_days: int = 5, plat_max_days: int = 15,
                                     plat_range_thresh: float = 0.08,
                                     overall_range_days: int = 15, overall_range_cap: float = 0.20) -> pd.Series:
    """
    æ¡ä»¶ï¼š
    1) è¿‘ run_daysï¼ˆ~10å‘¨â‰ˆ50ä¸ªäº¤æ˜“æ—¥ï¼‰ç´¯è®¡æ¶¨å¹… >= run_threshï¼ˆ60%ï¼‰
    2) è¿‘ 1-3 å‘¨ï¼ˆ5-15æ—¥ï¼‰é«˜ä½æŒ¯å¹…/å‡ä»· <= plat_range_threshï¼ˆ8%ï¼‰
    """
    close = ohlc["close"].astype(float)
    # å¼ºåŠ¿æ®µï¼šè¿‘ run_daysï¼ˆâ‰ˆ15å‘¨ï¼‰æœ€å¤§æ¶¨å¹…ï¼ˆç›¸å¯¹ run_days å‰æ”¶ç›˜ï¼‰
    # å®šä¹‰ï¼š (è¿‘run_dayså†…æœ€é«˜æ”¶ç›˜ / run_dayså‰æ”¶ç›˜ - 1) >= run_thresh
    past = close.shift(run_days)
    win_max = close.rolling(run_days).max()
    run_ret_max = (win_max / past) - 1.0
    strong = run_ret_max >= run_thresh

    # å³°å€¼åçš„å›æ’¤ä¸Šé™ï¼ˆè¿‘ run_days çª—å£å†…ï¼‰ï¼š
    # è®¡ç®—çª—å£å†…ï¼šä»å³°å€¼ï¼ˆçª—å£æœ€é«˜æ”¶ç›˜ï¼‰åˆ°å…¶åçš„æœ€ä½æ”¶ç›˜çš„å›æ’¤æ¯”ä¾‹ â‰¤ 25%
    def dd_after_peak(arr: np.ndarray) -> float:
        if arr.size == 0:
            return np.nan
        i = int(np.argmax(arr))
        peak = arr[i]
        if peak <= 0 or i == arr.size - 1:
            # æ²¡æœ‰åç»­æˆ–å¼‚å¸¸ï¼ŒæŒ‰0å›æ’¤å¤„ç†
            after_min = arr[-1]
        else:
            after_min = float(np.min(arr[i:]))
        if peak <= 0:
            return 0.0
        return (peak - after_min) / peak

    dd_series = close.rolling(run_days, min_periods=run_days).apply(dd_after_peak, raw=True)
    dd_ok = dd_series <= 0.25
    # å¹³å°æ®µï¼šåœ¨ 5/10/15 å¤©çª—å£ä¸­ä»»ä¸€æ»¡è¶³ä½æŒ¯å¹…
    conds = []
    for w in (plat_min_days, (plat_min_days + plat_max_days)//2, plat_max_days):
        high_n = ohlc["high"].rolling(w).max()
        low_n = ohlc["low"].rolling(w).min()
        mean_n = close.rolling(w).mean()
        range_pct = (high_n - low_n) / mean_n
        conds.append(range_pct <= plat_range_thresh)
    platform = conds[0]
    for c in conds[1:]:
        platform = platform | c

    # æ€»ä½“æ³¢åŠ¨ä¸Šé™ï¼šæœ€è¿‘ overall_range_days å¤©æœ€é«˜-æœ€ä½ä¸è¶…è¿‡ overall_range_capï¼ˆ20%ï¼‰
    hi_all = ohlc["high"].rolling(overall_range_days).max()
    lo_all = ohlc["low"].rolling(overall_range_days).min()
    overall_ok = ((hi_all - lo_all) / lo_all) <= overall_range_cap

    return (strong & platform & overall_ok & dd_ok).fillna(False)


# æ³¨å†Œåˆ°æ˜ å°„ä¸åˆ«å
PATTERN_MAP["å¼ºåŠ¿åå¹³å°"] = pattern_strong_run_then_platform
PATTERN_MAP["å¼ºåŠ¿å¹³å°"] = pattern_strong_run_then_platform
PATTERN_MAP["åå‘¨æ¶¨60å¹³å°"] = pattern_strong_run_then_platform
PATTERN_MAP["10å‘¨æ¶¨60å¹³å°"] = pattern_strong_run_then_platform
