#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´æ›´æ–°æ‰€æœ‰è‚¡ç¥¨æ•°æ® - å¸¦é™é€Ÿæ§åˆ¶
éµå®ˆ Tushare API é™åˆ¶: æ¯åˆ†é’Ÿæœ€å¤š 50 æ¬¡è°ƒç”¨
"""
import os
import sys
import time
import pandas as pd
from datetime import datetime, timedelta
from tqdm import tqdm

# è®¾ç½® Tushare Token
os.environ['TUSHARE_TOKEN'] = 'b09f3c651f9fa367d9861d845052e8b4bb461543980a2daad4fff9c7'

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'analyse_marketing'))

try:
    from analyse_marketing.utils import get_pro, cache_path, save_parquet, load_parquet, fetch_daily_history
except:
    import tushare as ts
    
def limit_sleep(call_count, start_time, min_interval=1.2):
    """
    é™é€Ÿæ§åˆ¶ï¼šæ¯åˆ†é’Ÿæœ€å¤š 50 æ¬¡è°ƒç”¨
    - æ¯æ¬¡è°ƒç”¨é—´éš”æœ€å°‘ 1.2 ç§’ï¼ˆè¿™æ ·æ¯åˆ†é’Ÿæœ€å¤š 50 æ¬¡ï¼‰
    """
    elapsed = time.time() - start_time
    sleep_needed = call_count * min_interval - elapsed
    if sleep_needed > 0:
        time.sleep(sleep_needed)
    
    # æ¯åˆ†é’Ÿé‡ç½®è®¡æ•°
    if elapsed >= 60:
        return 0, time.time()
    return call_count, start_time

def get_pro_simple():
    """è·å– Tushare API"""
    import tushare as ts
    token = os.environ.get('TUSHARE_TOKEN')
    if not token:
        raise RuntimeError("âŒ æœªè®¾ç½® TUSHARE_TOKEN")
    return ts.pro_api(token)

def fetch_all_stocks_latest():
    """è·å–æ‰€æœ‰è‚¡ç¥¨çš„æœ€æ–°æ•°æ®"""
    print("=" * 80)
    print("ğŸ“Š å®Œæ•´æ›´æ–°æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼ˆå¸¦é™é€Ÿï¼‰")
    print("=" * 80)
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”‘ é™é€Ÿ: æ¯åˆ†é’Ÿæœ€å¤š 50 æ¬¡ API è°ƒç”¨")
    print()
    
    pro = get_pro_simple()
    cache_dir = "analyse_marketing/cache"
    
    # è·å–æ‰€æœ‰ç¼“å­˜çš„è‚¡ç¥¨åˆ—è¡¨
    daily_dir = os.path.join(cache_dir, 'daily')
    os.makedirs(daily_dir, exist_ok=True)
    
    all_files = [f for f in os.listdir(daily_dir) if f.endswith('.parquet')]
    print(f"ğŸ“ æ‰¾åˆ° {len(all_files)} åªç¼“å­˜è‚¡ç¥¨")
    
    # ç»Ÿè®¡éœ€è¦æ›´æ–°çš„
    needs_update = []
    for file in all_files:
        code = file.replace('.parquet', '')
        cpath = os.path.join(daily_dir, file)
        try:
            df = pd.read_parquet(cpath)
            last_date = df.index[-1] if len(df) > 0 else 0
        except:
            last_date = 0
        needs_update.append((code, last_date))
    
    print(f"ğŸ”„ éœ€è¦æ£€æŸ¥æ›´æ–°: {len(needs_update)} åªè‚¡ç¥¨\n")
    
    # æ›´æ–°é€»è¾‘
    updated_count = 0
    failed_count = 0
    call_count = 0
    minute_start = time.time()
    
    pbar = tqdm(total=len(needs_update), desc="è¿›åº¦")
    
    for code, last_date in needs_update:
        try:
            # é™é€Ÿæ§åˆ¶
            call_count += 1
            if call_count > 50:
                print(f"\nâ³ è¾¾åˆ°åˆ†é’Ÿé™åˆ¶ï¼Œç­‰å¾…ä¸­...")
                time.sleep(62)  # ç­‰å¾…è¶…è¿‡ 1 åˆ†é’Ÿ
                call_count = 0
                minute_start = time.time()
            else:
                # æ­£å¸¸é—´éš”
                elapsed = time.time() - minute_start
                expected_time = call_count * 1.2
                if expected_time > elapsed:
                    time.sleep(expected_time - elapsed)
            
            # å°è¯•å¢é‡æ‹‰å–
            cpath = os.path.join(daily_dir, f"{code}.parquet")
            
            if os.path.exists(cpath):
                df = pd.read_parquet(cpath)
                if len(df) > 0:
                    last_trade_date = df.index[-1]
                    # ä»æœ€åæ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹æ‹‰å–
                    start_date_str = str(int(last_trade_date) + 1)
                else:
                    start_date_str = "20230101"
            else:
                start_date_str = "20230101"
            
            # è°ƒç”¨ API
            df_new = pro.daily(ts_code=code, start_date=start_date_str, fields='ts_code,trade_date,open,high,low,close,vol,amount')
            
            if df_new is not None and len(df_new) > 0:
                if os.path.exists(cpath):
                    df_old = pd.read_parquet(cpath)
                    df_combined = pd.concat([df_old, df_new], ignore_index=True).drop_duplicates(subset=['trade_date'])
                    df_combined = df_combined.sort_values('trade_date')
                else:
                    df_combined = df_new.sort_values('trade_date')
                
                df_combined['trade_date'] = pd.to_datetime(df_combined['trade_date'])
                df_combined = df_combined.set_index('trade_date')
                save_parquet(df_combined, cpath)
                updated_count += 1
        
        except Exception as e:
            failed_count += 1
            pass
        
        pbar.update(1)
    
    pbar.close()
    
    print("\n" + "=" * 80)
    print(f"âœ… æ›´æ–°å®Œæˆ!")
    print(f"  æˆåŠŸæ›´æ–°: {updated_count} åª")
    print(f"  å¤±è´¥: {failed_count} åª")
    print(f"â° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

if __name__ == "__main__":
    try:
        fetch_all_stocks_latest()
        
        # æ›´æ–°å®Œæˆåé‡æ–°è®¡ç®—å¸‚åœºå®½åº¦
        print("\nğŸ“ˆ ç°åœ¨é‡æ–°è®¡ç®—å¸‚åœºå®½åº¦...")
        os.system("python3 scripts/update_breadth_today.py")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)

