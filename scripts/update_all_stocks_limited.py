#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´æ›´æ–°æ‰€æœ‰è‚¡ç¥¨æ•°æ® - å¸¦é™é€Ÿæ§åˆ¶ï¼ˆä¿®å¤ ts_code/æ—¥æœŸç´¢å¼•ï¼‰
éµå®ˆ Tushare API é™åˆ¶: æ¯åˆ†é’Ÿæœ€å¤š 50 æ¬¡è°ƒç”¨
"""
import os
import sys
import time
import pandas as pd
from datetime import datetime, timedelta
from tqdm import tqdm

# ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ Tokenï¼›æ— åˆ™å›é€€åˆ°é»˜è®¤å€¼ï¼ˆç”¨æˆ·æä¾›ï¼‰
if not os.environ.get('TUSHARE_TOKEN'):
	os.environ['TUSHARE_TOKEN'] = 'b09f3c651f9fa367d9861d845052e8b4bb461543980a2daad4fff9c7'

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'analyse_marketing'))


def _to_ts_code(code: str) -> str:
	"""å°† 000001_SZ -> 000001.SZï¼›ä¿æŒå·²æ˜¯ç‚¹å·æ ¼å¼ä¸å˜ã€‚"""
	if '_' in code and '.' not in code:
		return code.replace('_', '.')
	return code


def _last_trade_date_from_df(df: pd.DataFrame) -> str:
	"""ä» DataFrame è§£ææœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œè¿”å› YYYYMMDD å­—ç¬¦ä¸²ã€‚"""
	# ä¼˜å…ˆ trade_date åˆ—
	if 'trade_date' in df.columns:
		val = df['trade_date'].iloc[-1]
		try:
			d = pd.to_datetime(val)
			return d.strftime('%Y%m%d')
		except Exception:
			pass
	# å°è¯•ç´¢å¼•ä¸ºæ—¥æœŸ
	try:
		idx = df.index
		d = pd.to_datetime(idx[-1])
		return d.strftime('%Y%m%d')
	except Exception:
		return '19700101'


def _next_yyyymmdd(yyyymmdd: str) -> str:
	try:
		d = datetime.strptime(yyyymmdd, '%Y%m%d') + timedelta(days=1)
		return d.strftime('%Y%m%d')
	except Exception:
		return '20230101'


def get_pro_simple():
	"""è·å– Tushare API"""
	import tushare as ts
	token = os.environ.get('TUSHARE_TOKEN')
	if not token:
		raise RuntimeError("âŒ æœªè®¾ç½® TUSHARE_TOKEN")
	return ts.pro_api(token)


def fetch_all_stocks_latest(end_date: str = None):
	"""è·å–æ‰€æœ‰è‚¡ç¥¨çš„æœ€æ–°æ•°æ®ï¼Œå¢é‡æ›´æ–°åˆ° end_dateï¼ˆé»˜è®¤ä»Šæ—¥ï¼‰ã€‚"""
	print("=" * 80)
	print("ğŸ“Š å®Œæ•´æ›´æ–°æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼ˆå¸¦é™é€Ÿï¼‰")
	print("=" * 80)
	print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
	print(f"ğŸ”‘ é™é€Ÿ: æ¯åˆ†é’Ÿæœ€å¤š 50 æ¬¡ API è°ƒç”¨")
	print()
	
	pro = get_pro_simple()
	cache_dir = "analyse_marketing/cache"
	daily_dir = os.path.join(cache_dir, 'daily')
	os.makedirs(daily_dir, exist_ok=True)
	
	all_files = [f for f in os.listdir(daily_dir) if f.endswith('.parquet')]
	print(f"ğŸ“ æ‰¾åˆ° {len(all_files)} åªç¼“å­˜è‚¡ç¥¨")
	
	needs_update = []
	for file in all_files:
		code = file.replace('.parquet', '')
		cpath = os.path.join(daily_dir, file)
		try:
			df = pd.read_parquet(cpath)
			last_date = _last_trade_date_from_df(df)
		except Exception:
			last_date = '19700101'
		needs_update.append((code, last_date))
	
	print(f"ğŸ”„ éœ€è¦æ£€æŸ¥æ›´æ–°: {len(needs_update)} åªè‚¡ç¥¨\n")
	
	updated_count = 0
	failed_count = 0
	call_count = 0
	minute_start = time.time()
	
	if end_date is None:
		end_date = datetime.today().strftime('%Y%m%d')
	
	pbar = tqdm(total=len(needs_update), desc="è¿›åº¦")
	
	for code, last_date in needs_update:
		try:
			# é™é€Ÿæ§åˆ¶
			call_count += 1
			if call_count > 50:
				print(f"\nâ³ è¾¾åˆ°åˆ†é’Ÿé™åˆ¶ï¼Œç­‰å¾…ä¸­...")
				time.sleep(62)
				call_count = 0
				minute_start = time.time()
			else:
				elapsed = time.time() - minute_start
				expected_time = call_count * 1.2
				if expected_time > elapsed:
					time.sleep(expected_time - elapsed)
			
			cpath = os.path.join(daily_dir, f"{code}.parquet")
			start_date_str = _next_yyyymmdd(last_date)
			ts_code = _to_ts_code(code)
			
			# æ‹‰å–å¢é‡
			df_new = pro.daily(ts_code=ts_code, start_date=start_date_str, end_date=end_date,
							 fields='ts_code,trade_date,open,high,low,close,vol,amount')
			
			if df_new is not None and len(df_new) > 0:
				# ç»Ÿä¸€åˆ—
				df_new = df_new.copy()
				df_new['trade_date'] = pd.to_datetime(df_new['trade_date'])
				df_new = df_new.sort_values('trade_date')
				df_new = df_new.set_index('trade_date')
				# å…¼å®¹åˆ—å
				df_new = df_new.rename(columns={'vol': 'vol'})
				
				if os.path.exists(cpath):
					df_old = pd.read_parquet(cpath)
					# è‹¥æ—§æ–‡ä»¶æ— æ—¥æœŸç´¢å¼•ï¼Œå°è¯•ä» trade_date åˆ—æ¢å¤
					if 'trade_date' in df_old.columns:
						df_old = df_old.copy()
						df_old['trade_date'] = pd.to_datetime(df_old['trade_date'])
						df_old = df_old.set_index('trade_date')
					# åˆå¹¶å»é‡
					df_combined = pd.concat([df_old, df_new], axis=0)
					df_combined = df_combined[~df_combined.index.duplicated(keep='last')]
					df_combined = df_combined.sort_index()
				else:
					df_combined = df_new
				
				# ä¿å­˜ï¼ˆä¿æŒä¸ç³»ç»Ÿè¯»å–å…¼å®¹çš„åˆ—åï¼šopen/high/low/close/volï¼‰
				df_save = df_combined[['open', 'high', 'low', 'close', 'vol', 'amount', 'ts_code']].copy()
				df_save.to_parquet(cpath)
				updated_count += 1
		
		except Exception:
			failed_count += 1
			# å¿½ç•¥ä¸ªåˆ«å¤±è´¥ï¼Œç»§ç»­
		
		pbar.update(1)
	
	pbar.close()
	
	print("\n" + "=" * 80)
	print(f"âœ… æ›´æ–°å®Œæˆ!")
	print(f"  æˆåŠŸæ›´æ–°: {updated_count} åª")
	print(f"  å¤±è´¥: {failed_count} åª")
	print(f"â° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
	print("=" * 80)


if __name__ == "__main__":
	try:
		# æŠŠæ•°æ®è¡¥åˆ° 2025-10-31
		fetch_all_stocks_latest(end_date='20251031')
		
		# æ›´æ–°å®Œæˆåé‡æ–°è®¡ç®—å¸‚åœºå®½åº¦ï¼ˆå…¨é‡ï¼Œåç»­å¯æŒ‰éœ€å‰”é™¤STï¼‰
		print("\nğŸ“ˆ ç°åœ¨é‡æ–°è®¡ç®—å¸‚åœºå®½åº¦...")
		os.system("python3 scripts/update_breadth_today.py")
		# å¦‚ç”Ÿæˆäº† _new æ–‡ä»¶ï¼Œåˆ™è‡ªåŠ¨æ›¿æ¢
		new_fp = "data/market/breadth_am_integrated_new.parquet"
		old_fp = "data/market/breadth_am_integrated.parquet"
		if os.path.exists(new_fp):
			try:
				os.replace(new_fp, old_fp)
				print("âœ“ å·²ç”¨æœ€æ–°å®½åº¦æ–‡ä»¶æ›¿æ¢æ—§æ–‡ä»¶")
			except Exception:
				pass
		
	except Exception as e:
		print(f"âŒ é”™è¯¯: {e}")
		sys.exit(1)

