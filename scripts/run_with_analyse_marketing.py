#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aè‚¡çŸ­çº¿äº¤æ˜“ç³»ç»Ÿ - ä¸analyse_marketingé›†æˆç‰ˆæœ¬
èåˆanalyse_marketingçš„çœŸå®æ•°æ®ã€å€™é€‰æ± ä¸çŸ­çº¿äº¤æ˜“ç­–ç•¥
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
from datetime import datetime, timedelta

from src.dataio import load_from_analyse_marketing, load_daily_candidates, convert_tushare_format
from src.breadth import compute_breadth
from src.signals import make_signals
from src.risk import apply_regime_filter, position_scale
from src.orders import export_orders_today
from src.backtest import simple_backtest

print("=" * 80)
print("ğŸ¬ Aè‚¡çŸ­çº¿äº¤æ˜“ç³»ç»Ÿ - analyse_marketingé›†æˆç‰ˆæœ¬")
print("=" * 80)

# ========== ç¬¬1æ­¥ï¼šåŠ è½½analyse_marketingæ•°æ® ==========
print("\n[æ­¥éª¤1/6] åŠ è½½analyse_marketingçœŸå®æ•°æ®...")

# è‡ªåŠ¨å®šä½analyse_marketingç›®å½•
am_base = os.path.join(os.path.dirname(__file__), "..", "analyse_marketing")
am_cache = os.path.join(am_base, "cache", "daily")
am_out = os.path.join(am_base, "out")

print(f"  - æ•°æ®ç¼“å­˜ç›®å½•: {am_cache}")
print(f"  - è¾“å‡ºç›®å½•: {am_out}")

# åŠ è½½é¢æ¿æ•°æ®
panels = load_from_analyse_marketing(cache_dir=am_cache, min_records=60)

if not panels:
    print("\nâœ— æ— æ³•åŠ è½½é¢æ¿æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ analyse_marketing/main.py ç”Ÿæˆç¼“å­˜")
    print("  æç¤ºï¼špython3 ../analyse_marketing/main.py --start 20230101 --export ./out")
    sys.exit(1)

print(f"  âœ“ æˆåŠŸåŠ è½½ {len(panels)} åªè‚¡ç¥¨çš„é¢æ¿æ•°æ®")

# åˆå¹¶æ”¶ç›˜ä»·ä¸æˆäº¤é‡
closes = pd.concat({k: v["close"] for k, v in panels.items()}, axis=1).dropna(how="all")
volumes = pd.concat({k: v["volume"] for k, v in panels.items()}, axis=1).reindex_like(closes)

print(f"  âœ“ é¢æ¿å½¢çŠ¶: {closes.shape[0]} äº¤æ˜“æ—¥ Ã— {closes.shape[1]} åªè‚¡ç¥¨")

# ========== ç¬¬2æ­¥ï¼šåŠ è½½analyse_marketingå€™é€‰æ±  ==========
print("\n[æ­¥éª¤2/6] åŠ è½½analyse_marketingå€™é€‰æ± ...")

candidates = load_daily_candidates(output_dir=am_out)

if candidates:
    # è¿‡æ»¤åˆ°å€™é€‰æ± ä¸­çš„è‚¡ç¥¨
    valid_codes = [c for c in closes.columns if c in candidates]
    if valid_codes:
        closes = closes[valid_codes]
        volumes = volumes[valid_codes]
        print(f"  âœ“ è¿‡æ»¤åˆ°å€™é€‰æ± : {len(valid_codes)} ä¸ªæ ‡çš„")
    else:
        print(f"  âš ï¸  å€™é€‰æ± ä¸­çš„ä»£ç ä¸é¢æ¿æ•°æ®ä¸åŒ¹é…ï¼Œä½¿ç”¨å…¨éƒ¨é¢æ¿")
else:
    print(f"  âš ï¸  æœªæ‰¾åˆ°å€™é€‰æ± ï¼Œä½¿ç”¨æ‰€æœ‰é¢æ¿æ•°æ®")

# ========== ç¬¬3æ­¥ï¼šè®¡ç®—å¸‚åœºå®½åº¦ ==========
print("\n[æ­¥éª¤3/6] è®¡ç®—å¸‚åœºå®½åº¦ä¸æƒ…ç»ª...")

pct_change = closes.pct_change() * 100
up_count = (pct_change > 0).sum(axis=1)
down_count = (pct_change < 0).sum(axis=1)
total = (pct_change.notna()).sum(axis=1)

ad_ratio = (up_count - down_count) / total

# 52å‘¨é«˜ä½
roll_max = closes.rolling(252, min_periods=20).max()
roll_min = closes.rolling(252, min_periods=20).min()
nh_252 = (closes >= (roll_max * 0.999)).sum(axis=1)
nl_252 = (closes <= (roll_min * 1.001)).sum(axis=1)

nh_ratio = nh_252 / total.clip(lower=1)
nl_ratio = nl_252 / total.clip(lower=1)

# Z-score å¾—åˆ†
def zscore(s):
    m = s.rolling(min(252, len(s)//2), min_periods=5).mean()
    sd = s.rolling(min(252, len(s)//2), min_periods=5).std().replace(0, np.nan)
    return (s - m) / sd

breadth_score = 0.5 * zscore(ad_ratio).clip(-3,3) + 0.3 * zscore(nh_ratio - nl_ratio).clip(-3,3)
breadth_score_ema = breadth_score.ewm(span=5, adjust=False, min_periods=5).mean()

# å¸‚åœºæ€åŠ¿
regime = pd.Series(index=breadth_score_ema.index, dtype="object")
regime[breadth_score_ema > 0.5] = "Bull"
regime[breadth_score_ema < -0.5] = "Bear"
regime[(breadth_score_ema <= 0.5) & (breadth_score_ema >= -0.5)] = "Neutral"

breadth = pd.DataFrame({
    "up_count": up_count,
    "down_count": down_count,
    "ad_ratio": ad_ratio,
    "nh_ratio": nh_ratio,
    "breadth_score_ema": breadth_score_ema,
    "regime": regime,
})  # ç§»é™¤ .dropna() ä»¥ä¿ç•™æ‰€æœ‰æ—¥æœŸ

print(f"  âœ“ å®½åº¦è®¡ç®—å®Œæˆ: {len(breadth)} æ—¥")
if len(breadth) > 0:
    print(f"  âœ“ æœ€è¿‘æ€åŠ¿: {breadth['regime'].iloc[-1]} (å¾—åˆ†: {breadth['breadth_score_ema'].iloc[-1]:.2f})")

os.makedirs("data/market", exist_ok=True)
breadth.to_parquet("data/market/breadth_am_integrated.parquet")

# ========== ç¬¬4æ­¥ï¼šç”Ÿæˆé€‰è‚¡ä¿¡å· ==========
print("\n[æ­¥éª¤4/6] ç”Ÿæˆé€‰è‚¡ä¿¡å·...")

ma5 = closes.rolling(5).mean()
ma20 = closes.rolling(20).mean()
mom5 = closes.pct_change(5)
vol20 = closes.pct_change().rolling(20).std()
vr = volumes / volumes.rolling(20).mean()

# æ’åºæ‰“åˆ†
q_mom = mom5.rank(axis=1, pct=True)
q_vol = vol20.rank(axis=1, pct=True)
score = q_mom - q_vol

# å…¥åœºä¸å‡ºåœºä¿¡å·
entries = (ma5 > ma20) & (q_mom > 0.6) & (q_vol < 0.8) & (vr > 1)
exits = ma5 < ma20

print(f"  âœ“ å…¥åœºä¿¡å·: {entries.sum().sum():.0f} ä¸ª")
print(f"  âœ“ å‡ºåœºä¿¡å·: {exits.sum().sum():.0f} ä¸ª")

# ========== ç¬¬5æ­¥ï¼šé£æ§è¿‡æ»¤ ==========
print("\n[æ­¥éª¤5/6] åº”ç”¨é£æ§è¿‡æ»¤...")

reg = breadth["regime"].reindex(entries.index).ffill()

# ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å‘é‡åŒ–æ–¹å¼è¿›è¡Œè¡Œçº§åˆ«çš„è¿‡æ»¤
# åˆ›å»ºä¸€ä¸ª boolean æ•°ç»„ï¼Œæ¯è¡Œéƒ½æ˜¯ (reg != "Bear") çš„å€¼
not_bear_mask = (reg != "Bear").values.reshape(-1, 1)  # è½¬æ¢ä¸ºåˆ—å‘é‡ä»¥ä¾¿å¹¿æ’­
entries_filtered = entries & not_bear_mask

mask_top = score.apply(lambda s: s.rank(ascending=False) <= 20, axis=1)
entries_top = entries_filtered & mask_top

print(f"  âœ“ è¿‡æ»¤åå…¥åœºä¿¡å·: {entries_top.sum().sum():.0f} ä¸ª")

# ä»“ä½ç¼©æ”¾
sig = 1 / (1 + np.exp(-breadth["breadth_score_ema"]))
position_scale_factor = (0.2 + sig).clip(0, 1)

print(f"  âœ“ ä»“ä½ç¼©æ”¾èŒƒå›´: {position_scale_factor.min():.2%} ~ {position_scale_factor.max():.2%}")

# ========== ç¬¬6æ­¥ï¼šå¯¼å‡ºè®¢å• ==========
print("\n[æ­¥éª¤6/6] ç”Ÿæˆå¹¶å¯¼å‡ºè®¢å•...")

today = entries_top.index[-1]
picks_mask = entries_top.loc[today].fillna(False)

# å¤„ç†NaNå€¼ï¼ˆå¯èƒ½æ‰€æœ‰å€¼éƒ½æ˜¯NaNï¼‰
if picks_mask.isna().all():
    picks_mask = pd.Series(False, index=picks_mask.index)
else:
    picks_mask = picks_mask.fillna(False)

picks = picks_mask[picks_mask].index.tolist()

if len(picks) == 0:
    print(f"  âš ï¸  ä»Šæ—¥æ— å…¥åœºä¿¡å· (å¸‚åœºæ€åŠ¿: {breadth['regime'].iloc[-1]})")
else:
    picks = score.loc[today][picks].nlargest(20).index.tolist()
    n_picks = len(picks)
    alloc = round(1 / n_picks, 4)
    
    orders_df = pd.DataFrame({
        "code": picks,
        "target_weight": alloc,
        "order_type": "buy",
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    })
    
    orders_df.to_csv("data/orders_am_integrated.csv", index=False, encoding="utf-8-sig")
    
    print(f"  âœ“ å·²å¯¼å‡º {n_picks} ä¸ªä¿¡å·åˆ° data/orders_am_integrated.csv")
    print(f"  âœ“ æ¯ä¸ªæ ‡çš„æƒé‡: {alloc:.2%}")
    print(f"\n  ğŸ“‹ è®¢å•é¢„è§ˆ (å‰10ä¸ª):")
    print(orders_df.head(10).to_string(index=False))

# ========== ç”ŸæˆæŠ¥å‘Š ==========
print("\n" + "=" * 80)
print("ğŸ“Š analyse_marketingé›†æˆ - è¿è¡Œå®Œæˆ")
print("=" * 80)

print(f"\nğŸ“ˆ å¸‚åœºçŠ¶æ€:")
if len(breadth) > 0:
    print(f"  - äº¤æ˜“æ—¥: {today.strftime('%Y-%m-%d')}")
    print(f"  - å¸‚åœºæ€åŠ¿: {breadth['regime'].iloc[-1]}")
    print(f"  - å®½åº¦å¾—åˆ†: {breadth['breadth_score_ema'].iloc[-1]:.2f}")
    print(f"  - ä¸Šæ¶¨: {int(breadth['up_count'].iloc[-1])}, ä¸‹è·Œ: {int(breadth['down_count'].iloc[-1])}")

print(f"\nğŸ’° ä»“ä½ç®¡ç†:")
if len(position_scale_factor) > 0:
    print(f"  - ä»Šæ—¥ç¼©æ”¾: {position_scale_factor.iloc[-1]:.2%}")

print(f"\nğŸ“‚ è¾“å‡ºæ–‡ä»¶:")
print(f"  - å¸‚åœºæŒ‡æ ‡: data/market/breadth_am_integrated.parquet")
print(f"  - è®¢å•æ–‡ä»¶: data/orders_am_integrated.csv")
print(f"  - å€™é€‰æ± : {am_out}/daily_candidates.csv")

print("\nâœ… é›†æˆå®Œæˆï¼")
print("=" * 80)

print("\nğŸ’¡ åç»­æ­¥éª¤:")
print("  1. æŸ¥çœ‹ data/orders_am_integrated.csv è·å–ä»Šæ—¥äº¤æ˜“è®¢å•")
print("  2. å®šæœŸè¿è¡Œ analyse_marketing/main.py æ›´æ–°æ•°æ®ç¼“å­˜")
print("  3. è°ƒæ•´å‚æ•°åé‡æ–°è¿è¡Œæœ¬è„šæœ¬")

print("\nâœ¨ ç¥äº¤æ˜“é¡ºåˆ©! ğŸ“ˆ\n")
