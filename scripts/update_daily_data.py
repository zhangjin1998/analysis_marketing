#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ TuShare daily æ¥å£æ›´æ–°æœ€æ–°çš„æ—¥çº¿æ•°æ®åˆ° analyse_marketing ç¼“å­˜
æ”¯æŒè‡ªåŠ¨é‡è¯•å’ŒåŠ¨æ€å»¶è¿Ÿè°ƒæ•´ä»¥åº”å¯¹APIé™æµ
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import tushare as ts
from datetime import datetime, timedelta
import time

# ========== é…ç½® ==========
TUSHARE_TOKEN = os.environ.get('TUSHARE_TOKEN', '')
if not TUSHARE_TOKEN:
    print("âŒ é”™è¯¯: æœªè®¾ç½® TUSHARE_TOKEN ç¯å¢ƒå˜é‡")
    print("   è¯·è¿è¡Œ: export TUSHARE_TOKEN='your_token'")
    sys.exit(1)

pro = ts.pro_api(TUSHARE_TOKEN)
CACHE_DIR = os.path.join(os.path.dirname(__file__), "..", "analyse_marketing", "cache", "daily")
os.makedirs(CACHE_DIR, exist_ok=True)

print(f"ğŸ“Š æ›´æ–°æ—¥çº¿æ•°æ®åˆ°æœ€æ–°")
print(f"   ç¼“å­˜ç›®å½•: {CACHE_DIR}")

# ========== 1. åŠ è½½å€™é€‰æ±  ==========
candidate_file = os.path.join(os.path.dirname(__file__), "..", "analyse_marketing", "out", "daily_candidates.csv")
if not os.path.exists(candidate_file):
    print(f"âŒ æ‰¾ä¸åˆ°å€™é€‰æ± æ–‡ä»¶: {candidate_file}")
    print("   è¯·å…ˆè¿è¡Œ: cd analyse_marketing && python3 main.py --start 20250101 --export ./out --offline")
    sys.exit(1)

candidates_df = pd.read_csv(candidate_file)
candidate_codes = candidates_df['ts_code'].tolist()

print(f"âœ“ åŠ è½½å€™é€‰æ± : {len(candidate_codes)} ä¸ªæ ‡çš„")

# ========== 2. ç¡®å®šæ—¥æœŸèŒƒå›´ ==========
end_date = datetime.today().strftime("%Y%m%d")
start_date = (datetime.today() - timedelta(days=365*3)).strftime("%Y%m%d")

print(f"âœ“ æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date}")

# ========== 3. æ›´æ–°æ¯ä¸ªæ ‡çš„çš„æ—¥çº¿æ•°æ®ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰==========
print(f"\nğŸ“¥ å¼€å§‹æ›´æ–°æ—¥çº¿æ•°æ®...")
success_count = 0
fail_count = 0
failed_codes = []

for i, code in enumerate(candidate_codes, 1):
    retries = 0
    max_retries = 3
    delay = 0.5  # åˆå§‹å»¶è¿Ÿ
    
    while retries < max_retries:
        try:
            # è·å–æ•°æ®
            df = pro.daily(ts_code=code, start_date=start_date, end_date=end_date)
            
            if df is None or len(df) == 0:
                fail_count += 1
                failed_codes.append(code)
                print(f"  âš ï¸  [{i:3d}/{len(candidate_codes)}] {code}: æ— æ•°æ®")
                break
            
            # é‡å‘½ååˆ—ä»¥åŒ¹é…æ ‡å‡†æ ¼å¼
            df_std = df[['trade_date', 'open', 'high', 'low', 'close', 'vol', 'amount']].copy()
            df_std.columns = ['trade_date', 'open', 'high', 'low', 'close', 'volume', 'amount']
            df_std['trade_date'] = pd.to_datetime(df_std['trade_date'])
            df_std['pct_chg'] = df_std['close'].pct_change().fillna(0) * 100
            
            # ä¿å­˜åˆ° parquet
            cache_file = os.path.join(CACHE_DIR, f"{code}.parquet")
            df_std.to_parquet(cache_file, index=False)
            
            success_count += 1
            if i % 10 == 0:
                print(f"  âœ“ å·²æ›´æ–° {i}/{len(candidate_codes)} ä¸ªæ ‡çš„...")
            
            # æˆåŠŸåé‡ç½®å»¶è¿Ÿ
            delay = 0.5
            break
            
        except Exception as e:
            error_msg = str(e)
            retries += 1
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºé™æµé”™è¯¯
            if 'æ¯åˆ†é’Ÿæœ€å¤šè®¿é—®' in error_msg or 'è®¿é—®é¢‘ç‡è¿‡é«˜' in error_msg:
                if retries < max_retries:
                    delay = min(delay * 2, 5.0)  # æŒ‡æ•°å¢é•¿å»¶è¿Ÿï¼Œæœ€å¤š5ç§’
                    print(f"  â³ [{i:3d}/{len(candidate_codes)}] {code}: APIé™æµï¼Œ{delay}ç§’åé‡è¯•... (ç¬¬{retries}æ¬¡)")
                    time.sleep(delay)
                    continue
                else:
                    print(f"  âŒ [{i:3d}/{len(candidate_codes)}] {code}: é‡è¯•{max_retries}æ¬¡ä»å¤±è´¥")
                    fail_count += 1
                    failed_codes.append(code)
                    break
            else:
                # å…¶ä»–é”™è¯¯
                fail_count += 1
                failed_codes.append(code)
                print(f"  âš ï¸  [{i:3d}/{len(candidate_codes)}] {code}: {error_msg[:40]}")
                break
    
    # æ­£å¸¸å»¶è¿Ÿï¼ˆé¿å…é™æµï¼‰
    if retries == 0:  # æˆåŠŸçš„è¯·æ±‚
        time.sleep(0.3)

print(f"\nâœ… æ›´æ–°å®Œæˆ!")
print(f"   æˆåŠŸ: {success_count} / {len(candidate_codes)} ä¸ª")
print(f"   å¤±è´¥: {fail_count} / {len(candidate_codes)} ä¸ª")

if failed_codes:
    print(f"\nâš ï¸  å¤±è´¥çš„æ ‡çš„:")
    for code in failed_codes:
        print(f"   - {code}")
    
    print(f"\nğŸ’¡ å¯ä»¥ç¨åé‡æ–°è¿è¡Œè„šæœ¬ä»¥é‡è¯•å¤±è´¥çš„æ ‡çš„:")
    print(f"   TUSHARE_TOKEN='b09f3c651f9fa367d9861d845052e8b4bb461543980a2daad4fff9c7' python3 scripts/update_daily_data.py")

print(f"\nâœ¨ ç°åœ¨å¯ä»¥è¿è¡Œäº¤æ˜“ç³»ç»Ÿ:")
print(f"   python3 scripts/run_with_analyse_marketing.py")
