#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¤– å¤šæ¨¡å‹é…ç½®ç®¡ç†æ¨¡å—
æ”¯æŒåˆ‡æ¢ä¸åŒçš„å¤§æ¨¡å‹ (DeepSeek, OpenAI, Claude, Qwen ç­‰)
"""

import os
from typing import Optional, Dict, Any
from src.config import get_with_env, get_config_value  # æ–°å¢


# ========== æ¨¡å‹é…ç½® ==========

MODEL_CONFIGS = {
    # ğŸ‡¨ğŸ‡³ DeepSeek (å›½å†…ï¼Œæœ€ä¾¿å®œï¼Œè´¨é‡æ¥è¿‘ GPT-4)
    "deepseek": {
        "provider": "openai",  # OpenAI å…¼å®¹ API
        "api_key": get_with_env("deepseek.api_key", "DEEPSEEK_API_KEY"),
        "base_url": get_with_env("deepseek.base_url", "DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1"),
        "model": get_with_env("deepseek.model", "DEEPSEEK_MODEL", "deepseek-chat"),
        "temperature": 0.3,
        "max_tokens": 2000,
        "cost": "$0 (Â¥500å…è´¹)",
        "speed": "å¿«",
        "quality": "â­â­â­â­â­",
        "notes": "æ¨èé¦–é€‰ï¼Œå›½å†…æœåŠ¡å™¨ï¼Œä¸­æ–‡ä¼˜åŒ–",
    },
    
    # ğŸŒ OpenAI (å›½é™…æ ‡å‡†ï¼Œè´¨é‡æœ€å¥½)
    "openai": {
        "provider": "openai",
        "api_key": get_with_env("openai.api_key", "OPENAI_API_KEY"),
        "base_url": get_with_env("openai.base_url", "OPENAI_BASE_URL", "https://api.openai.com/v1"),
        "model": get_with_env("openai.model", "OPENAI_MODEL", "gpt-3.5-turbo"),
        "temperature": 0.3,
        "max_tokens": 2000,
        "cost": "$5-20/æœˆ",
        "speed": "ä¸­",
        "quality": "â­â­â­â­â­",
        "notes": "å›½é™…æ ‡å‡†ï¼Œæ€§èƒ½ç¨³å®š",
    },
    
    # ğŸ‡¨ğŸ‡³ é˜¿é‡Œé€šä¹‰åƒé—® (å…è´¹é¢åº¦ï¼Œå¿«é€Ÿ)
    "qwen": {
        "provider": "openai",
        "api_key": get_with_env("qwen.api_key", "QWEN_API_KEY"),
        "base_url": get_with_env("qwen.base_url", "QWEN_BASE_URL", "https://dashscope.aliyuncs.com/api/v1"),
        "model": get_with_env("qwen.model", "QWEN_MODEL", "qwen-plus"),
        "temperature": 0.3,
        "max_tokens": 2000,
        "cost": "$0 (å…è´¹é¢åº¦)",
        "speed": "å¾ˆå¿«",
        "quality": "â­â­â­â­",
        "notes": "å›½å†…å…è´¹ï¼Œå¾ˆå¿«ï¼Œä¸­æ–‡ä¼˜åŒ–",
    },
    
    # ğŸ‡¨ğŸ‡³ è®¯é£æ˜Ÿç« (æˆæœ¬ä½ï¼Œæ”¯æŒé•¿æ–‡æœ¬)
    "spark": {
        "provider": "openai",
        "api_key": get_with_env("spark.api_key", "SPARK_API_KEY"),
        "base_url": get_with_env("spark.base_url", "SPARK_BASE_URL", "https://spark-api.xf-yun.com/v1"),
        "model": get_with_env("spark.model", "SPARK_MODEL", "4.0Ultra"),
        "temperature": 0.3,
        "max_tokens": 2000,
        "cost": "$$ ä½",
        "speed": "å¿«",
        "quality": "â­â­â­â­",
        "notes": "æˆæœ¬ä½ï¼Œæ”¯æŒè¶…é•¿æ–‡æœ¬",
    },
    
    # ğŸ‡¨ğŸ‡³ ç™¾åº¦æ–‡å¿ƒä¸€è¨€ (åŠŸèƒ½å®Œæ•´)
    "baidu": {
        "provider": "baidu",
        "api_key": get_with_env("baidu.api_key", "BAIDU_API_KEY"),
        "base_url": get_with_env("baidu.base_url", "BAIDU_BASE_URL", "https://aip.baidubce.com/rpc/2.0"),
        "model": get_with_env("baidu.model", "BAIDU_MODEL", "ernie-bot-4"),
        "temperature": 0.3,
        "max_tokens": 2000,
        "cost": "$ ä½",
        "speed": "å¿«",
        "quality": "â­â­â­â­",
        "notes": "åŠŸèƒ½å®Œæ•´ï¼Œç”Ÿæ€å¥½",
    },
    
    # ğŸ‡¨ğŸ‡³ Claude (Anthropicï¼Œæ¨ç†èƒ½åŠ›æœ€å¼º)
    "claude": {
        "provider": "anthropic",
        "api_key": get_with_env("claude.api_key", "ANTHROPIC_API_KEY"),
        "base_url": get_with_env("claude.base_url", "ANTHROPIC_BASE_URL", "https://api.anthropic.com"),
        "model": get_with_env("claude.model", "ANTHROPIC_MODEL", "claude-3-5-sonnet-20241022"),
        "temperature": 0.3,
        "max_tokens": 2000,
        "cost": "$$$ ä¸­",
        "speed": "ä¸­",
        "quality": "â­â­â­â­â­",
        "notes": "æ¨ç†èƒ½åŠ›æœ€å¼ºï¼Œæ€è€ƒæ·±å…¥",
    },
}


# ========== æ¨¡å‹å·¥å‚å‡½æ•° ==========

def get_llm(model_name: str = "deepseek"):
    """
    æ ¹æ®æ¨¡å‹åç§°è·å– LLM å®ä¾‹
    
    Args:
        model_name: æ¨¡å‹åç§° (deepseek/openai/qwen/spark/baidu/claude)
    
    Returns:
        LLM å®ä¾‹
    
    Raises:
        ValueError: æ¨¡å‹åç§°ä¸å­˜åœ¨
    """
    from langchain.llms import OpenAI, Anthropic
    
    if model_name not in MODEL_CONFIGS:
        raise ValueError(
            f"âŒ æœªçŸ¥æ¨¡å‹: {model_name}\n"
            f"å¯ç”¨æ¨¡å‹: {', '.join(MODEL_CONFIGS.keys())}"
        )
    
    config = MODEL_CONFIGS[model_name]
    
    # æ£€æŸ¥ API Key
    if not config["api_key"]:
        raise ValueError(
            f"âŒ ç¼ºå°‘ API Key: {model_name}\n"
            f"è¯·åœ¨ config.json ä¸­é…ç½®å¯¹åº”å­—æ®µï¼Œæˆ–è®¾ç½®ç¯å¢ƒå˜é‡ {model_name.upper()}_API_KEY"
        )
    
    # æ ¹æ®æä¾›å•†åˆ›å»º LLM å®ä¾‹
    if config["provider"] == "anthropic":
        return Anthropic(
            api_key=config["api_key"],
            model=config["model"],
        )
    
    elif config["provider"] == "baidu":
        # ç™¾åº¦éœ€è¦ç‰¹æ®Šå¤„ç†
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…ä½¿ç”¨éœ€è¦ç™¾åº¦å®˜æ–¹ SDK
        from langchain.llms import OpenAI
        # æ³¨: ç™¾åº¦ä¸å®Œå…¨å…¼å®¹ OpenAI APIï¼Œå»ºè®®ä½¿ç”¨ç™¾åº¦å®˜æ–¹ SDK
        pass
    
    else:  # OpenAI å…¼å®¹çš„ API
        return OpenAI(
            api_key=config["api_key"],
            base_url=config["base_url"],
            model=config["model"],
            temperature=config["temperature"],
            max_tokens=config["max_tokens"],
        )


def list_models():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
    from tabulate import tabulate
    
    headers = ["æ¨¡å‹", "æä¾›å•†", "æˆæœ¬", "é€Ÿåº¦", "è´¨é‡", "å¤‡æ³¨"]
    rows = []
    
    for name, cfg in MODEL_CONFIGS.items():
        rows.append([
            name,
            cfg["provider"],
            cfg["cost"],
            cfg["speed"],
            cfg["quality"],
            cfg["notes"][:30] + "..." if len(cfg["notes"]) > 30 else cfg["notes"]
        ])
    
    return tabulate(rows, headers=headers, tablefmt="grid")


def check_models():
    """æ£€æŸ¥æ‰€æœ‰æ¨¡å‹çš„ API Key é…ç½®çŠ¶æ€"""
    print("\nğŸ“‹ æ¨¡å‹ API Key é…ç½®çŠ¶æ€æ£€æŸ¥")
    print("=" * 70)
    
    for name, cfg in MODEL_CONFIGS.items():
        has_key = "âœ…" if cfg["api_key"] else "âŒ"
        
        # è·å–æ­£ç¡®çš„ç¯å¢ƒå˜é‡å
        if name == "deepseek":
            env_var = "DEEPSEEK_API_KEY"
        elif name == "openai":
            env_var = "OPENAI_API_KEY"
        elif name == "qwen":
            env_var = "QWEN_API_KEY"
        elif name == "spark":
            env_var = "SPARK_API_KEY"
        elif name == "baidu":
            env_var = "BAIDU_API_KEY"
        elif name == "claude":
            env_var = "ANTHROPIC_API_KEY"
        else:
            env_var = f"{cfg['provider'].upper()}_API_KEY"
        
        print(f"{has_key} {name:15} ({cfg['provider']:10}) -> {env_var}")
    
    print("=" * 70)


def get_default_model():
    """è·å–é»˜è®¤æ¨¡å‹"""
    return get_with_env("model.name", "TRADING_MODEL", "deepseek")


# ========== ä¸»å‡½æ•°ç¤ºä¾‹ ==========
if __name__ == "__main__":
    import sys
    
    # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
    print("\n" + "=" * 70)
    print("ğŸ¤– å¯ç”¨çš„ AI æ¨¡å‹")
    print("=" * 70 + "\n")
    print(list_models())
    
    # æ£€æŸ¥é…ç½®
    print("\n")
    check_models()
    
    # æµ‹è¯•æ¨¡å‹
    print("\nğŸ“Š é»˜è®¤æ¨¡å‹: ", get_default_model())
